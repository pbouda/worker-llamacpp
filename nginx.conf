upstream llama {
    server 127.0.0.1:8080;
}

server {
    listen 80;

    # RunPod health check: proxy to llama-server /health
    # Maps 502 (server not up yet) and 503 (model loading) to 204 (initializing)
    location = /ping {
        proxy_pass http://llama/health;
        proxy_intercept_errors on;
        error_page 502 503 =204 @initializing;
    }

    location @initializing {
        return 204;
    }

    # Proxy all other requests to llama-server
    location / {
        proxy_pass http://llama;
        proxy_http_version 1.1;
        proxy_buffering off;
        proxy_read_timeout 330s;
        proxy_connect_timeout 10s;
        proxy_send_timeout 30s;
        proxy_set_header Connection '';
        proxy_set_header Host $host;
    }
}
